exp7 svm

import pandas as pd  
import numpy as np  
from sklearn.model_selection import train_test_split  
from sklearn.preprocessing import StandardScaler  
from sklearn.svm import SVC  
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score  
from sklearn.preprocessing import label_binarize  
import matplotlib.pyplot as plt  
from sklearn.metrics import roc_curve, auc  

df = pd.read_csv("Student_performance_data _.csv")  
X = df.drop(['StudentID', 'GradeClass'], axis=1)  
y = df['GradeClass']  

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  

scaler = StandardScaler()  
X_train = scaler.fit_transform(X_train)  
X_test = scaler.transform(X_test)  

model = SVC(kernel='linear', probability=True)  
model.fit(X_train, y_train)  

y_pred = model.predict(X_test)  

cm = confusion_matrix(y_test, y_pred)  
print("Confusion Matrix:\n", cm)  

print("Classification Report:\n", classification_report(y_test, y_pred))  

print("Accuracy: {:.2f}".format(accuracy_score(y_test, y_pred)))  

y_test_bin = label_binarize(y_test, classes=sorted(y.unique()))  
n_classes = y_test_bin.shape[1]  

fpr = {}  
tpr = {}  
roc_auc = {}  
for i in range(n_classes):  
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], model.predict_proba(X_test)[:, i])  
    roc_auc[i] = auc(fpr[i], tpr[i])  

plt.figure()  
for i in range(n_classes):  
    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')  
plt.plot([0, 1], [0, 1], 'k--')  
plt.xlabel('False Positive Rate')  
plt.ylabel('True Positive Rate')  
plt.title('ROC Curve')  
plt.legend()  
plt.show()  


exp8 nsvm

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

file_path = "pulsar_data_train.csv"
df = pd.read_csv(file_path)

df.fillna(df.mean(), inplace=True)

X = df.iloc[:, :-1]
y = df.iloc[:, -1]

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)

kernels = ['rbf', 'poly', 'sigmoid']

for kernel in kernels:
    clf = SVC(kernel=kernel, C=10, gamma='scale', coef0=0)
    clf.fit(X_train, y_train)

    y_pred = clf.predict(X_test)
    print(f"Classification Report for {kernel} kernel:")
    print(classification_report(y_test, y_pred))

    cm = confusion_matrix(y_test, y_pred)

    cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)
    cmd.plot(cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix for {kernel} kernel')
    plt.show()

    plt.figure(figsize=(10, 6))
    plt.title(f"SVM Decision Boundary with {kernel} Kernel")
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')

    x_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1
    y_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)

    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='k')
    plt.show()


exp9 ffn

import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns

file_name = "survey lung cancer.csv"
data = pd.read_csv(file_name)
print(data.head())

data['GENDER'] = data['GENDER'].map({'M': 1, 'F': 0})
data['LUNG_CANCER'] = data['LUNG_CANCER'].map({'YES': 1, 'NO': 0})

x = data.drop(columns=['LUNG_CANCER']).values
y = data['LUNG_CANCER'].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

scaler = StandardScaler()
x = scaler.fit_transform(x_train)

model = tf.keras.Sequential([
    tf.keras.layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()

history = model.fit(x_train, y_train, epochs=20, batch_size=16, validation_data=(x_test, y_test))

train_acc = model.evaluate(x_train, y_train, batch_size=32)[1]
test_acc = model.evaluate(x_test, y_test, batch_size=32)[1]
print('Training accuracy:', train_acc)
print('Testing accuracy:', test_acc)

y_pred = (model.predict(x_test) > 0.5).astype("int32")
print(classification_report(y_test, y_pred))

conf_matrix = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:\n', conf_matrix)

plt.figure(figsize=(4, 3))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['No Lung Cancer', 'Lung Cancer'],
            yticklabels=['No Lung Cancer', 'Lung Cancer'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.tight_layout()
plt.show()

y_score = model.predict(x_test)
fpr, tpr, _ = roc_curve(y_test, y_score)
roc_auc = roc_auc_score(y_test, y_score)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()



exp10 rnn

import numpy as np  
import tensorflow as tf  
print(tf.__version__)    
from tensorflow import keras  
from tensorflow.keras import layers  
import matplotlib.pyplot as plt  

np.random.seed(42)  
X = np.linspace(-1.5, 1.5, 200)  
y = np.sin(3 * np.pi * X) + np.random.normal(0, 0.1, size=X.shape)  
X = X.reshape(-1, 1)  

X_train, X_test = X[:160], X[160:]  
y_train, y_test = y[:160], y[160:]  

def build_overfitting_model():  
    model = keras.Sequential([  
        layers.Dense(256, activation='relu', input_shape=(1,)),  
        layers.Dense(256, activation='relu'),  
        layers.Dense(256, activation='relu'),  
        layers.Dense(1)  
    ])  
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])  
    return model  

model_overfit = build_overfitting_model()  
history_overfit = model_overfit.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), verbose=0)  

def build_regularized_model():  
    model = keras.Sequential([  
        layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01), input_shape=(1,)),  
        layers.Dropout(0.3),  
        layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),  
        layers.Dropout(0.3),  
        layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),  
        layers.Dropout(0.3),  
        layers.Dense(1)  
    ])  
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])  
    return model  

model_regularized = build_regularized_model()  
history_regularized = model_regularized.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), verbose=0)  

overfit_test_loss = model_overfit.evaluate(X_test, y_test, verbose=0)  
regularized_test_loss = model_regularized.evaluate(X_test, y_test, verbose=0)  

print("Test Loss (Overfitting Model):", overfit_test_loss[0])  
print("Test Loss (Regularized Model):", regularized_test_loss[0])  

plt.figure(figsize=(12, 5))  
plt.subplot(1, 2, 1)  
plt.plot(history_overfit.history['loss'], label='Train Loss')  
plt.plot(history_overfit.history['val_loss'], label='Validation Loss')  
plt.title('Overfitting Model Training Loss')  
plt.xlabel('Epochs')  
plt.ylabel('Loss')  
plt.legend()  

plt.subplot(1, 2, 2)  
plt.plot(history_regularized.history['loss'], label='Train Loss')  
plt.plot(history_regularized.history['val_loss'], label='Validation Loss')  
plt.title('Regularized Model Training Loss')  
plt.xlabel('Epochs')  
plt.ylabel('Loss')  
plt.legend()  

plt.tight_layout()  
plt.show()  

y_overfit_pred = model_overfit.predict(X_test)  
y_regularized_pred = model_regularized.predict(X_test)  

plt.figure(figsize=(14, 6))  
plt.subplot(1, 2, 1)  
plt.scatter(X_test, y_test, color='blue', label='True Values')  
plt.scatter(X_test, y_overfit_pred, color='red', label='Overfitting Model Predictions')  
plt.title('Overfitting Model Predictions')  
plt.xlabel('X')  
plt.ylabel('y')  
plt.legend()  

plt.subplot(1, 2, 2)  
plt.scatter(X_test, y_test, color='blue', label='True Values')  
plt.scatter(X_test, y_regularized_pred, color='green', label='Regularized Model Predictions')  
plt.title('Regularized Model Predictions')  
plt.xlabel('X')  
plt.ylabel('y')  
plt.legend()  

plt.tight_layout()  
plt.show()  


exp11 cnn

import os
import zipfile
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import label_binarize
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models

# === Step 1: Define dataset path ===
with zipfile.ZipFile('C:/Users/abiji/OneDrive/Documents/Animals.zip', 'r') as zip_ref:
    zip_ref.extractall("C:/Users/abiji/OneDrive/Documents/Animals")
dataset_path = "C:/Users/abiji/OneDrive/Documents/Animals"


# === Step 2: Load dataset ===
batch_size = 32
img_height, img_width = 150, 150

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_data = datagen.flow_from_directory(
    dataset_path,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True)

val_data = datagen.flow_from_directory(
    dataset_path,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=False)

class_names = list(train_data.class_indices.keys())
num_classes = len(class_names)

print(f"Detected classes: {class_names}")

# === Step 3: Build CNN model ===
model = models.Sequential([
    layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_height, img_width, 3)),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(train_data, validation_data=val_data, epochs=10)

# === Step 4: Evaluation ===
val_data.reset()
pred_probs = model.predict(val_data)
y_pred = np.argmax(pred_probs, axis=1)
y_true = val_data.classes
y_true_bin = label_binarize(y_true, classes=range(num_classes))

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.tight_layout()
plt.show()

# Classification Report
print("Classification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))

# ROC Curve and AUC
fpr = {}
tpr = {}
roc_auc = {}
for i in range(num_classes):
    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], pred_probs[:, i])
    roc_auc[i] = roc_auc_score(y_true_bin[:, i], pred_probs[:, i])

# Plot ROC curves
plt.figure(figsize=(8, 6))
for i in range(num_classes):
    plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multiclass ROC Curve')
plt.legend()
plt.tight_layout()
plt.show()


exp12 hm

import numpy as np  
from hmmlearn import hmm  
states = ["Sunny", "Rainy", "Cloudy"]  
observations = ["shorts", "coat", "umbrella"]  
obs_map = {o: i for i, o in enumerate(observations)}  
sequence = ["coat", "coat", "umbrella"]  
obs_seq = np.array([obs_map[o] for o in sequence]).reshape(-1, 1)  
model = hmm.CategoricalHMM(n_components=3, init_params='', n_iter=1)  
model.startprob_ = np.array([0.33, 0.33, 0.34])  

model.transmat_ = np.array([  
    [0.8, 0.15, 0.05],   # Sunny  
    [0.38, 0.6, 0.02],   # Rainy  
    [0.75, 0.05, 0.2]    # Cloudy  
])  

model.emissionprob_ = np.array([  
    [0.1, 0.8, 0.1],   # Sunny  
    [0.1, 0.2, 0.7],   # Rainy  
    [0.4, 0.5, 0.1]    # Cloud  
])  

predicted_states = model.predict(obs_seq)  
log_prob = model.score(obs_seq)  
probability = np.exp(log_prob)  # Convert from log probability to regular probability  

print("Observation sequence:", sequence)  
print("Predicted weather states:", [states[i] for i in predicted_states])  
print("Log probability of the observation sequence:", log_prob)  
print("Probability of the observation sequence:", probability)
